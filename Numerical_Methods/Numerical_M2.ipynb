{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saheed Adisa Ganiyu\n",
    "### Numerical Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary modules\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_Pnorm(x, p=2):\n",
    "    \"\"\"\n",
    "    This function computes the p_norm of a vector: 1<=p<=\\infty\n",
    "    \n",
    "    INPUT:\n",
    "        \n",
    "        - `x` vector\n",
    "        \n",
    "        - `p` - the type of norm to be computed.\n",
    "        If `p` is omited, it will be computed. because, it has a default value as 2\n",
    "        \n",
    "    OUTPUT:\n",
    "            -It returns a scalar value.\n",
    "    \"\"\"\n",
    "    if p == float(\"inf\"):\n",
    "        return max(x)\n",
    "    x = np.array(x)\n",
    "    res = (np.sum(x**p)**(1/p))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem 1 Write a MATLAB or Python program that performs power terations, given a matrix $A$, initial guess vector $x$, tolerance Tol, and maximum number of iterations $N_{\\max }$.\\\n",
    "As the stopping criterium let us use the discrepancy between $A x$ and $\\lambda x$, i.e. for $x$ normalized so that $\\|x\\|_2=1$\\\n",
    "(1) compute $\\operatorname{Err}=A x-\\lambda x$\\\n",
    "(2) if $\\|E r r\\|_2 \\leq$ Tol then exit the iterations.\\\n",
    "Please use the routine you wrote to find the largest eigenvalue and the corresponding eigenvector of the following matrix:\n",
    "$$\n",
    "A=\\left(\\begin{array}{rrrrrr}\n",
    "-3 & -3 & -2 & -1 & 0 & 1 \\\\\n",
    "-3 & 0 & -1 & 0 & 1 & 2 \\\\\n",
    "-2 & -1 & 3 & 1 & 2 & 3 \\\\\n",
    "-1 & 0 & 1 & 6 & 3 & 4 \\\\\n",
    "0 & 1 & 2 & 3 & 9 & 5 \\\\\n",
    "1 & 2 & 3 & 4 & 5 & 12\n",
    "\\end{array}\\right)\n",
    "$$\n",
    "As the initial guess, use $x=(1,2,3,4,5,6)^T$. (Do not forget to normalize it first).\\\n",
    "Let's use Tol $=10^{-8}, N_{\\max }=50$. Print out the eigenvalue and eigenvector you found, and the number of iterations it took to converge.\\\n",
    "\n",
    "Organize your code as a function that runs iterations for an arbitrary matrix and initial guess, and a calling script."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 1\n",
    "We implement this algorithm for power iteration.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text { Algo}&\\text{rithm} 27.1. \\text{Power Iteration }\\\\\n",
    "v^{(0)}= &\\text { some vector with }\\left\\|v^{(0)}\\right\\|=1\\\\\n",
    "\\text { for } k&=1,2, \\ldots\\\\\n",
    "&w=A v^{(k-1)} \\quad \\text { apply } A\\\\\n",
    "&v^{(k)}=w /\\|w\\| \\quad \\text { normalize }\\\\\n",
    "&\\lambda^{(k)}=\\left(v^{(k)}\\right)^T A v^{(k)} \\quad \\text { Rayleigh quotient }\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pow_iter(A, x, N=50, Tol= 10**(-8)):\n",
    "    \"\"\"\n",
    "    This function finds the largest eigenvalue and its corresponding eigenvector using Power iteration method.\n",
    "    \n",
    "    INPUT:\n",
    "    \n",
    "        - `A` a sqaure matrix.\n",
    "        - `x` the initial guess vector.\n",
    "        - `N` maximum number of iteration.\n",
    "        - `Tol` tolerance for convergence.\n",
    "    OUTPUT:\n",
    "    \n",
    "        - `lamda_k` the largest Eigenvalue.\n",
    "        - `vk` the corresponding Eigenvector.\n",
    "        - `count` the number of iteration for convergence.\n",
    "    \"\"\"\n",
    "    N_max = N\n",
    "    x = np.array(x)\n",
    "    vk = x/vec_Pnorm(x)\n",
    "    count = 0\n",
    "    Err = 1000\n",
    "    Tol = Tol\n",
    "    lamda_k = 1\n",
    "    while (Err> Tol and count <= N_max):            # Checking for convergence\n",
    "        w = np.array(np.matmul(A,vk)).ravel()       # Applying A\n",
    "        vk = w/vec_Pnorm(w)                         # Normalizing\n",
    "        lamda_k = np.array(np.matmul(np.matmul(vk.T,A),vk)).ravel()  # Rayleigh quotient\n",
    "        count = count + 1                           # Num of Iteration counter\n",
    "        Err = (np.matmul(A,vk)) - (lamda_k*vk)\n",
    "        Err = vec_Pnorm(Err)                        # Error norm\n",
    "        #print(Err)\n",
    "    return vk, lamda_k[0], count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=\n",
      " [[-3 -3 -2 -1  0  1]\n",
      " [-3  0 -1  0  1  2]\n",
      " [-2 -1  3  1  2  3]\n",
      " [-1  0  1  6  3  4]\n",
      " [ 0  1  2  3  9  5]\n",
      " [ 1  2  3  4  5 12]]\n",
      "\n",
      " Initial_Vector=  [1, 2, 3, 4, 5, 6]\n",
      "\n",
      "===================Results======================================\n",
      "\n",
      " Eigen_Vector=  [-0.01724002  0.0957202   0.22290849  0.36719369  0.53227151  0.72298552]\n",
      "\n",
      " Eigen_Value=  18.878503170086887\n",
      "\n",
      " Num_iter=  18\n",
      "==================================================================\n"
     ]
    }
   ],
   "source": [
    "# Applying the given matrix and the initial guess vector\n",
    "A = np.mat([[-3,-3,-2,-1,0,1],[-3,0,-1,0,1,2],[-2,-1,3,1,2,3],[-1,0,1,6,3,4],[0,1,2,3,9,5],[1,2,3,4,5,12]])\n",
    "x = [1, 2, 3, 4, 5, 6]\n",
    "v,l,i=pow_iter(A, x)\n",
    "print(\"A=\\n\",A)\n",
    "print(\"\\n Initial_Vector= \",x)\n",
    "print(\"\\n===================Results======================================\")\n",
    "print(\"\\n Eigen_Vector= \",v)\n",
    "print(\"\\n Eigen_Value= \",l)\n",
    "print(\"\\n Num_iter= \",i)\n",
    "print(\"==================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Result:** from the given matrix $A$ and the initial vector $x$, we our largest eigenvalue $= 18.878503170086887$ and its corresponding eigenvector $= [-0.01724002, \\quad  0.0957202, \\quad  0.22290849, \\quad 0.36719369, \\quad 0.53227151, \\quad 0.72298552]$ with observed number of iteration $=18$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a MATLAB program (a function) that performs inverse iteration with a FIXED shift $\\mu$, on a given matrix $A$ and given initial guess vector $x$, tolerance Tol, and a maximum number of iterations $N_{\\max }$.\n",
    "\n",
    "As the stopping criterium let us use the discrepancy between $A x$ and $\\lambda x$, i.e. for $x$ normalized so that $\\|x\\|_2=1$\\\n",
    "(1) compute $E r r=A x-\\lambda x$\\\n",
    "(2) if $\\|E r r\\|_2 \\leq$ Tol then exit the iterations.\\\n",
    "Set shift $\\mu$ to $3.7$.\\\n",
    "Compute the inverse $B$ of $A-\\mu I$. (You are allowed to use MATLAB function \"inv()\" or \"numpy.linalg.inv()\" in Python for this).\n",
    "\n",
    "Run you power method iterations on matrix $B$, and find the eigenvalue of $A$ closest to 3.7, and the corresponding eigenvector.\n",
    "\n",
    "As the initial guess, use $x=(1,2,3,4,5,6)^T$. (Do not forget to normalize it first). Let's use Tol $=10^{-8}, N_{\\max }=50$.\n",
    "\n",
    "Organize your code as a function that runs iterations for an arbitrary matrix and initial guess, and a script that calls your function. Print out the eigenvalue and eigenvector you found, and the number of iterations it took to converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution 2\n",
    "Here we implement the following algorithm.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text { Algo}&\\text{rithm 27.2. Inverse Iteration }\\\\\n",
    "v^{(0)}=&\\text { some vector with }\\left\\|v^{(0)}\\right\\|=1\\\\\n",
    "\\text { for } k=&1,2, \\ldots\\\\\n",
    "&\\text { Solve }(A-\\mu I) w=v^{(k-1)} \\text { for } w \\quad \\text { apply }(A-\\mu I)^{-1}\\\\\n",
    "&v^{(k)}=w /\\|w\\| \\quad \\text { normalize }\\\\\n",
    "&\\lambda^{(k)}=\\left(v^{(k)}\\right)^T A v^{(k)} \\quad \\text { Rayleigh quotient }\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_iter(A, x, mu = 3.7, N=100, Tol= 10**(-8)):\n",
    "    \"\"\"\n",
    "    This function finds the eigenvalue of matrix A closest to a given fixed point mu \n",
    "    and its corresponding eigenvector using inverse iteration method.\n",
    "    \n",
    "    INPUT:\n",
    "    \n",
    "        - `A` a sqaure matrix.\n",
    "        - `x` the initial guess vector.\n",
    "        - `mu` a fixed shift point.\n",
    "        - `N` maximum number of iteration.\n",
    "        - `Tol` tolerance for convergence.\n",
    "    OUTPUT:\n",
    "    \n",
    "        - `lamda_k` the closest eigenvalue to the given fixed shift point mu.\n",
    "        - `vk` the corresponding Eigenvector.\n",
    "        - `count` the number of iteration for convergence.\n",
    "    \"\"\"\n",
    "    N_max = N\n",
    "    x = np.array(x)\n",
    "    vk = x/vec_Pnorm(x)\n",
    "    I = np.eye(np.shape(A)[0])\n",
    "    count = 0\n",
    "    Err = 1000\n",
    "    Tol = Tol\n",
    "    lamda_k = 1\n",
    "    B = np.linalg.inv(A - (mu*I))\n",
    "    while (Err> Tol and count <= N_max):                # Checking for convergence\n",
    "        w = np.array(np.matmul(B,vk)).ravel()           # Applying A\n",
    "        vk = w/vec_Pnorm(w)                             # Normalizing\n",
    "        lamda_k = np.array(np.matmul(np.matmul(vk.T,A),vk)).ravel()  # Rayleigh quotient\n",
    "        count = count + 1                               # Num of Iteration counter\n",
    "        Err = (np.matmul(A,vk)) - (lamda_k*vk)\n",
    "        Err = vec_Pnorm(Err)                            # Error norm\n",
    "    return vk, lamda_k[0], count\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Part_a:** Here, we apply inverse iteration on matrix $A$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=\n",
      " [[-3 -3 -2 -1  0  1]\n",
      " [-3  0 -1  0  1  2]\n",
      " [-2 -1  3  1  2  3]\n",
      " [-1  0  1  6  3  4]\n",
      " [ 0  1  2  3  9  5]\n",
      " [ 1  2  3  4  5 12]]\n",
      "\n",
      " Initial_Vector=  [1, 2, 3, 4, 5, 6]\n",
      "\n",
      "===================Results===================================\n",
      "\n",
      " Eigen_Vector=  [-0.11100168 -0.09131111 -0.03652608  0.91529329 -0.30140393 -0.22226251]\n",
      "\n",
      " Eigen_Value=  4.12214702965213\n",
      "\n",
      " Num_iter=  31\n",
      "==============================================================\n"
     ]
    }
   ],
   "source": [
    "# Applying inverse iteration method on the given matrix A and the initial guess vector x\n",
    "A = np.mat([[-3,-3,-2,-1,0,1],[-3,0,-1,0,1,2],[-2,-1,3,1,2,3],[-1,0,1,6,3,4],[0,1,2,3,9,5],[1,2,3,4,5,12]])\n",
    "x = [1, 2, 3, 4, 5, 6]\n",
    "v,l,i=inv_iter(A, x)\n",
    "print(\"A=\\n\",A)\n",
    "print(\"\\n Initial_Vector= \",x)\n",
    "print(\"\\n===================Results===================================\")\n",
    "print(\"\\n Eigen_Vector= \",v)\n",
    "print(\"\\n Eigen_Value= \",l)\n",
    "print(\"\\n Num_iter= \",i)\n",
    "print(\"==============================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** from the given matrix $A$ and the initial vector $x$, we have our largest eigenvalue $= 4.12214702965213\n",
    "$ and its corresponding eigenvector $= [-0.11100168, \\quad  -0.09131111, \\quad  -0.03652608, \\quad 0.91529329, \\quad -0.30140393, \\quad -0.22226251]$ with observed number of iteration $=31$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2) Part_b:** Here, we apply power iteration on inverse of matrix $B = A - \\mu I$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B=\n",
      " [[-2.42532937e-01  1.51930637e-01  2.44861565e-01 -2.81747029e-01\n",
      "   1.81144473e-03  3.87973326e-02]\n",
      " [ 1.51930637e-01 -4.14472093e-01  2.57974518e-01 -2.19222949e-01\n",
      "   3.77295336e-02  7.12450748e-02]\n",
      " [ 2.44861565e-01  2.57974518e-01 -1.12001838e+00  2.19413627e-02\n",
      "   1.76270734e-01  1.96400652e-01]\n",
      " [-2.81747029e-01 -2.19222949e-01  2.19413627e-02  1.98867693e+00\n",
      "  -6.08796067e-01 -5.12814284e-01]\n",
      " [ 1.81144473e-03  3.77295336e-02  1.76270734e-01 -6.08796067e-01\n",
      "   5.83162980e-01 -1.30929319e-01]\n",
      " [ 3.87973326e-02  7.12450748e-02  1.96400652e-01 -5.12814284e-01\n",
      "  -1.30929319e-01  3.53664373e-01]]\n",
      "\n",
      " Initial_Vector=  [1, 2, 3, 4, 5, 6]\n",
      "\n",
      "===================Results==============================================\n",
      "\n",
      " Eigen_Vector=  [-0.11100168 -0.09131111 -0.03652607  0.91529329 -0.30140393 -0.22226251]\n",
      "\n",
      " Eigen_Value=  2.3688429143373346\n",
      "\n",
      " Num_iter=  33\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "# Applying power iteration on the inverse of matrix ðµ=ð´âˆ’ðœ‡ð¼\n",
    "A = np.mat([[-3,-3,-2,-1,0,1],[-3,0,-1,0,1,2],[-2,-1,3,1,2,3],[-1,0,1,6,3,4],[0,1,2,3,9,5],[1,2,3,4,5,12]])\n",
    "x = [1, 2, 3, 4, 5, 6]\n",
    "I = np.eye(np.shape(A)[0])\n",
    "mu = 3.7\n",
    "B = np.linalg.inv(A - (mu*I))\n",
    "v,l,i=pow_iter(B, x)\n",
    "print(\"B=\\n\",B)\n",
    "print(\"\\n Initial_Vector= \",x)\n",
    "print(\"\\n===================Results==============================================\")\n",
    "print(\"\\n Eigen_Vector= \",v)\n",
    "print(\"\\n Eigen_Value= \",l)\n",
    "print(\"\\n Num_iter= \",i)\n",
    "print(\"===========================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The outcome here aserts the fact that the eigenvectors of $B = (A-\\mu I)^{-1}$ are the same as the eigenvectors of $A$, and the corresponding eigenvalues are $\\left\\{\\left(\\lambda_j-\\mu\\right)^{-1}\\right\\}$, where $\\left\\{\\lambda_j\\right\\}$ are the eigenvalues of $A$, for any $\\mu \\in \\mathbb{R}$. As we can see the result in **part_a** and  **part_b** of solution (2) where their eigenvector are the same and corresponding eigenvalue is indeed $\\left(\\lambda_j-\\mu\\right)^{-1} = 2.3688429143373346$ which shows that $\\lambda_j$ and $\\mu$ are not closed to each other as the resulted eigenvalue is not large.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3.\n",
    "Use the same algorithm and the same matrix as in Problem 2, but with shift $\\mu=$ 4.0. PLEASE COMMENT ON how the change of shift $\\mu$ has changed the number of iterations (comparing to problem 2) and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Part_a:** Here, we apply inverse iteration on matrix $A$ with $\\mu = 4.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A=\n",
      " [[-3 -3 -2 -1  0  1]\n",
      " [-3  0 -1  0  1  2]\n",
      " [-2 -1  3  1  2  3]\n",
      " [-1  0  1  6  3  4]\n",
      " [ 0  1  2  3  9  5]\n",
      " [ 1  2  3  4  5 12]]\n",
      "\n",
      " Initial_Vector=  [1, 2, 3, 4, 5, 6]\n",
      "\n",
      "===================Results==============================================\n",
      "\n",
      " Eigen_Vector=  [-0.11100168 -0.09131111 -0.03652607  0.91529329 -0.30140393 -0.22226251]\n",
      "\n",
      " Eigen_Value=  4.12214702965213\n",
      "\n",
      " Num_iter=  9\n",
      "==========================================================================\n"
     ]
    }
   ],
   "source": [
    "A = np.mat([[-3,-3,-2,-1,0,1],[-3,0,-1,0,1,2],[-2,-1,3,1,2,3],[-1,0,1,6,3,4],[0,1,2,3,9,5],[1,2,3,4,5,12]])\n",
    "x = [1, 2, 3, 4, 5, 6]\n",
    "v,l,i=inv_iter(A, x, mu=4.0 )\n",
    "print(\"A=\\n\",A)\n",
    "print(\"\\n Initial_Vector= \",x)\n",
    "print(\"\\n===================Results==============================================\")\n",
    "print(\"\\n Eigen_Vector= \",v)\n",
    "print(\"\\n Eigen_Value= \",l)\n",
    "print(\"\\n Num_iter= \",i)\n",
    "print(\"==========================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** from the given matrix $A$ and the initial vector $x$, we have our largest eigenvalue $= 4.12214702965213\n",
    "$ and its corresponding eigenvector $= [-0.11100168, \\quad  -0.09131111, \\quad  -0.03652607, \\quad 0.91529329, \\quad -0.30140393, \\quad -0.22226251]$ with observed number of iteration $=9$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark:** Here, we noticed that, as $\\mu = 4.0$ gets closer to corresponding eigenvalue$=4.12214702965213$. So, the rate of convergence becomes faster that is, from $33$ in solution$(2)$ to $9$  here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3) Part_b:** Here, we apply power iteration on inverse of matrix $B = A - \\mu I$ with $\\mu = 4.0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B=\n",
      " [[-0.13333333  0.2         0.2        -0.86666667  0.2         0.2       ]\n",
      " [ 0.2        -0.3         0.2        -0.7         0.2         0.2       ]\n",
      " [ 0.2         0.2        -0.8        -0.2         0.2         0.2       ]\n",
      " [-0.86666667 -0.7        -0.2         6.86666667 -2.2        -1.7       ]\n",
      " [ 0.2         0.2         0.2        -2.2         1.2         0.2       ]\n",
      " [ 0.2         0.2         0.2        -1.7         0.2         0.7       ]]\n",
      "\n",
      " Initial_Vector=  [1, 2, 3, 4, 5, 6]\n",
      "\n",
      "===================Results==============================================\n",
      "\n",
      " Eigen_Vector=  [-0.11100169 -0.09131111 -0.03652607  0.91529329 -0.30140393 -0.22226251]\n",
      "\n",
      " Eigen_Value=  8.186854832638703\n",
      "\n",
      " Num_iter=  10\n",
      "==========================================================================\n"
     ]
    }
   ],
   "source": [
    "# Applying power iteration on the inverse of matrix ðµ=ð´âˆ’ðœ‡ð¼\n",
    "A = np.mat([[-3,-3,-2,-1,0,1],[-3,0,-1,0,1,2],[-2,-1,3,1,2,3],[-1,0,1,6,3,4],[0,1,2,3,9,5],[1,2,3,4,5,12]])\n",
    "x = [1, 2, 3, 4, 5, 6]\n",
    "I = np.eye(np.shape(A)[0])\n",
    "mu = 4.0\n",
    "B = np.linalg.inv(A - (mu*I))\n",
    "v,l,i=pow_iter(B, x)\n",
    "print(\"B=\\n\",B)\n",
    "print(\"\\n Initial_Vector= \",x)\n",
    "print(\"\\n===================Results==============================================\")\n",
    "print(\"\\n Eigen_Vector= \",v)\n",
    "print(\"\\n Eigen_Value= \",l)\n",
    "print(\"\\n Num_iter= \",i)\n",
    "print(\"==========================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The outcome here aserts the fact that the eigenvectors of $B = (A-\\mu I)^{-1}$ are the same as the eigenvectors of $A$, and the corresponding eigenvalues are $\\left\\{\\left(\\lambda_j-\\mu\\right)^{-1}\\right\\}$, where $\\left\\{\\lambda_j\\right\\}$ are the eigenvalues of $A$, for any $\\mu \\in \\mathbb{R}$. As we can see the result in **part_a** and  **part_b** of solution (3) where their eigenvector are the same and corresponding eigenvalue is indeed $\\left(\\lambda_j-\\mu\\right)^{-1} = 8.186854832638703$ which shows that $\\lambda_j$ and $\\mu$ are not too closed to each other as the resulted eigenvalue is not too large. But it is closer than $\\mu = 3.7$ in problem(2) as we can see from the  fast rate of convergence which actually reduced the number of iteration to $10$ from $33$.\\\n",
    "Moreover, when we chose our $\\mu = 4.12$ very closed to $\\lambda_j$ we have the corresponding eigenvalue $=465.7597527859305$ with number of iteration$=4$ which shows their closeness as it reflects in the rate of convergence and the resulted eigenvalue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given\n",
    "$$\n",
    "\\left\\{\\begin{array}{ll}\n",
    "30 x_1-10+10 \\cos \\left(0.1 x_2+1\\right) & =0 \\\\\n",
    "20 x_2+15+5 \\sin \\left(0.1 x_1+0.1 x_3\\right) & =0 \\\\\n",
    "70 x_3-30+5 \\mathrm{e}^{-x_1^2} & =0\n",
    "\\end{array} .\\right.\n",
    "$$\n",
    "\n",
    "**(b)** Write a program in Python or Matlab that finds the solution of this system by a simple iteration with $g(x)=x-A f(x)$ where $A$ is either a constant or a constant matrix of your choice, and $f(x)$ is the left hand side of the above system. The initial guess should be $x^{(0)}=(1,1,1)$ and the iterations should be stopped when the condition $\\left\\|f\\left(x^{(\\nu)}\\right)\\right\\|_2 \\leq 10^{-6}$ is satisfied.\n",
    "\n",
    "Please, print out the number of iterations required to reach the desired accuracy. Submit the code and the printout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the given function in question 4(a)\n",
    "def f(x):\n",
    "    x = np.array(x)\n",
    "    f1 = 30*x[0] - 10 + 10*np.cos(0.1*x[1]+1)\n",
    "    f2 = 20*x[1] + 15 + 5*np.sin(0.1*x[0] + 0.1*x[2])\n",
    "    f3 = 70*x[2] - 30 + 5*np.exp(-(x[0])**2)\n",
    "    return np.array([f1,f2,f3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_iter(x,Nmax=50,Tol=10**(-6)):\n",
    "    \"\"\"\n",
    "    This function find roots of non linear equation using simple iteration method\n",
    "    \n",
    "    INPUT:\n",
    "        - `x` the initial guess vector.\n",
    "        - `Nmax` maximum number of iteration.\n",
    "        - `Tol` tolerance for convergence.\n",
    "    OUTPUT:\n",
    "        - `xn` the list of solution.\n",
    "        - `count` the number of iteration for convergence.\n",
    "    \"\"\"\n",
    "    Tol = Tol\n",
    "    Nmax = Nmax\n",
    "    x0 = np.array(x)\n",
    "    Err = 10; count =0\n",
    "    xn = np.array([1,1,1])\n",
    "    A = 0.02*np.eye(3)\n",
    "    while (Err>Tol and count<Nmax):\n",
    "        xn = x0- np.matmul(A,f(x0))\n",
    "        x0 =xn\n",
    "        Err = vec_Pnorm(f(xn))\n",
    "        count +=1\n",
    "    return xn, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================Results==========================\n",
      "Sol=  [ 0.13239547 -0.76226451  0.35838399]\n",
      "\n",
      "Num_iter=  34\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "# executing the given initial guess\n",
    "x0 = [1,1,1]\n",
    "x1,c1=simple_iter(x0, Nmax=100)\n",
    "print(\"\\n===================Results==========================\")\n",
    "print(\"Sol= \",x1)\n",
    "print(\"\\nNum_iter= \",c1)\n",
    "print(\"=====================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** here we chose our matrix $A$ to be a $3x3$ diagonal matrix with all its entries eqaul $0.02$. Then we have the solution to be $[ 0.13239547\\quad -0.76226451\\quad  0.35838399]$ with number of iteration equal $34$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 5 (a)** Write a program in Matlab that finds the solution of the system below by a simple iteration with $g(x)=x-A f(x)$ where $A$ is either a constant or a constant matrix of your choice, and $f(x)$ is the left hand side of the system:\n",
    "$$\n",
    "\\left\\{\\begin{array}{l}\n",
    "x_1-x_2-10+10 \\cos \\left(0.1 x_1\\right)=0 \\\\\n",
    "2 x_1+x_3-20+10 \\sin \\left(0.1 x_2\\right)=0 \\\\\n",
    "x_1-0.1 x_2+x_3-30+10 \\mathrm{e}^{-x_3^2}=0\n",
    "\\end{array} .\\right.\n",
    "$$\n",
    "The initial guess should be $x^{(0)}=(1,1,1)$ and the iterations should be stopped when the condition $\\left\\|f\\left(x^{(\\nu)}\\right)\\right\\|_2 \\leq 10^{-6}$ is satisfied. You do not have to prove anything, just find $A$ that makes the iteration converge. Please, print out the number of iterations required to reach the desired accuracy. Submit the code and the printout.\\\n",
    "**(b)** Numerically solve the system from part (a) using the Newton's method, with the same initial guess and stopping criterion. Please, print out the number of iterations required to reach the desired accuracy. Submit the code and the printout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the given function in question 5(a)\n",
    "def f2(x):\n",
    "    x = np.array(x)\n",
    "    f1 = x[0] - x[1] - 10 + 10*np.cos(0.1*x[0])\n",
    "    f2 = 2*x[0] + x[2] - 20 + 10*np.sin(0.1*x[1])\n",
    "    f3 = x[0] - 0.1*x[1] + x[2] - 30 + 10*np.exp(-(x[2])**2)\n",
    "    return np.array([f1,f2,f3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_iter2(x,Nmax=50,Tol=1e-6):\n",
    "    \"\"\"\n",
    "    This function find roots of non linear equation using simple iteration method\n",
    "    \n",
    "    INPUT:\n",
    "        - `x` the initial guess vector.\n",
    "        - `Nmax` maximum number of iteration.\n",
    "        - `Tol` tolerance for convergence.\n",
    "    OUTPUT:\n",
    "        - `xn` the list of solution.\n",
    "        - `count` the number of iteration for convergence.\n",
    "    \"\"\"\n",
    "    Tol = Tol\n",
    "    Nmax = Nmax\n",
    "    x0 = np.array(x)\n",
    "    Err = 10; count =0\n",
    "    xn = np.array([1,1,1])\n",
    "    A =  0.45*np.eye(3)\n",
    "    while (Err>Tol and count<Nmax):\n",
    "        xn = x0- np.matmul(A,f2(x0))\n",
    "        x0 =xn\n",
    "        Err = vec_Pnorm(f2(xn))\n",
    "        count = count + 1\n",
    "    return xn, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================Results==========================\n",
      "Sol=  [-4.38489108 -5.33094986 33.8517956 ]\n",
      "\n",
      "Num_iter=  44\n",
      "=====================================================\n"
     ]
    }
   ],
   "source": [
    "# executing the given initial guess\n",
    "x0 = [-4,-5,33]\n",
    "x2,c2=simple_iter2(x0, Nmax=100)\n",
    "print(\"\\n===================Results==========================\")\n",
    "print(\"Sol= \",x2)\n",
    "print(\"\\nNum_iter= \",c2)\n",
    "print(\"=====================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** here we carefully chose our matrix $A$ to be a $3x3$ diagonal matrix with all its entries eqaul $0.45$. Then we have the solution to be $[ -4.38489108\\quad -5.33094986\\quad  33.8517956]$ with number of iteration equal $44$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the given function in question 5(a)\n",
    "def f3(x):\n",
    "    x = np.array(x)\n",
    "    f1 = x[0] - x[1] - 10 + 10*np.cos(0.1*x[0])\n",
    "    f2 = 2*x[0] + x[2] - 20 + 10*np.sin(0.1*x[1])\n",
    "    f3 = x[0] - 0.1*x[1] + x[2] - 30 + 10*np.exp(-(x[2])**2)\n",
    "    return np.array([f1,f2,f3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the corresponding Jacobian matrix\n",
    "def j(x):\n",
    "    x = np.array(x)\n",
    "    jacb = np.array([[1-np.sin(0.1*x[0]), -1, 0],[2, np.cos(0.1*x[1]), 1], [1, -0.1, 1-20*x[2]*np.exp(-(x[2])**2)]])\n",
    "    return jacb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newton_methd(x,Nmax=50,Tol=1e-6):\n",
    "    \"\"\"\n",
    "    This function find roots of non linear equation using Newton iteration method\n",
    "    \n",
    "    INPUT:\n",
    "        - `x` the initial guess vector.\n",
    "        - `Nmax` maximum number of iteration.\n",
    "        - `Tol` tolerance for convergence.\n",
    "    OUTPUT:\n",
    "        - `xn` the list of solution.\n",
    "        - `count` the number of iteration for convergence.\n",
    "    \"\"\"\n",
    "    Tol = Tol\n",
    "    Nmax = Nmax\n",
    "    x0 = np.array(x)\n",
    "    Err = 10; count =0\n",
    "    xn = np.array([1,1,1])\n",
    "    while (Err>Tol and count<Nmax):\n",
    "        temp = np.linalg.inv(j(x0))\n",
    "        xn = x0- np.matmul(temp,f2(x0))\n",
    "        x0 =xn\n",
    "        Err = vec_Pnorm(f3(xn))\n",
    "        count +=1\n",
    "    return xn, count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================Results======================\n",
      "Sol=  [-4.38489174 -5.33095023 33.85179672]\n",
      "\n",
      "Num_iter=  6\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "# executing the given initial guess\n",
    "x0 = [1,1,1]\n",
    "x3,c3=newton_methd(x0, Nmax=100)\n",
    "print(\"\\n===================Results======================\")\n",
    "print(\"Sol= \",x3)\n",
    "print(\"\\nNum_iter= \",c3)\n",
    "print(\"=================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** with Newton method we can see a pretty improvement on the rate of cinvergence as the number iteration jumped to $6$ instead of $44$ in part_a of simple iteration in problem(5). Therefore, our solution is $[-4.38489174\\quad -5.33095023\\quad 33.85179672]\n",
    "$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
